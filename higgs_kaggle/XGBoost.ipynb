{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "In this notebook we prepare a simple solution for the [kaggle challenge on higgs.](https://inclass.kaggle.com/c/mlhep-2016-higgs-detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import root_numpy\n",
    "data = pandas.DataFrame(root_numpy.root2array('datasets/public_train_100000.root'))\n",
    "#data = data[:50000]\n",
    "test = pandas.DataFrame(root_numpy.root2array('datasets/public_test.root'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = list(set(data.columns) - {'event_id', 'target'})\n",
    "#features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare high-level features for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#high_level_features = ['m_jj', 'm_jjj', 'm_jlv', 'm_wwbb', 'm_bb', 'm_wbb', 'm_lv']\n",
    "#high_level_features_a = ['m_jj', 'm_jjj', 'm_jlv', 'm_wwbb', 'm_bb', 'm_wbb', 'm_lv', 'lepton_pt','mem_pt']\n",
    "#high_level_features_b = ['m_jj', 'm_jjj', 'm_jlv', 'm_wwbb', 'm_bb', 'm_wbb', 'lepton_pt','mem_pt','jet1_pt','jet2_pt','jet3_pt','jet4_pt']\n",
    "#high_level_features_c = ['m_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_wwbb', 'm_bb', 'm_wbb', 'lepton_pt','mem_pt','jet1_pt','jet2_pt','jet3_pt','jet4_pt']\n",
    "#high_level_features_d = ['m_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_wwbb', 'm_bb', 'm_wbb', 'lepton_pt','mem_pt','jet1_pt','jet2_pt','jet3_pt','jet4_pt','j_HT','phi_bb']\n",
    "#high_level_features_e = ['m_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_wwbb', 'm_bb', 'm_wbb', 'lepton_pt','mem_pt','jet1_pt','jet2_pt','jet3_pt','jet4_pt','j_HT','phi_bb','LT']\n",
    "data['j_HT'] = data['jet1_pt'] + data['jet2_pt'] + data['jet3_pt'] + data['jet4_pt']\n",
    "test['j_HT'] = test['jet1_pt'] + test['jet2_pt'] + test['jet3_pt'] + test['jet4_pt']\n",
    "data['phi_bb'] = data['jet1_phi'] + data['jet2_phi'] + data['jet3_phi'] + data['jet4_phi']\n",
    "test['phi_bb'] = test['jet1_phi'] + test['jet2_phi'] + test['jet3_phi'] + test['jet4_phi']\n",
    "data['LT'] = data['lepton_pt'] + data['mem_pt']\n",
    "test['LT'] = test['lepton_pt'] + test['mem_pt']\n",
    "high_level_features = ['m_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_wwbb', 'm_bb', 'm_wbb', 'jet1_pt','jet2_pt','jet3_pt','jet4_pt','j_HT','phi_bb','lepton_pt','mem_pt','LT']#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide training data into 2 parts \n",
    "`train_test_split` function is used to divide into 2 parts to preserve quality overestimating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data, validation_data = train_test_split(data, random_state=11, train_size=0.66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.78987067160674362, 0.0017453148557578547)\n"
     ]
    }
   ],
   "source": [
    "from rep.estimators import XGBoostClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "xgboost_cv = cross_val_score(XGBoostClassifier(max_depth = 6, min_child_weight = 1, gamma=0.3, colsample=1, nthreads=10),\n",
    "                             training_data[high_level_features].astype(np.float64),\n",
    "                             training_data.target.astype(np.int64), cv=4, scoring=\"roc_auc\")\n",
    "print(xgboost_cv.mean(), xgboost_cv.std())\n",
    "\n",
    "#0.7668823025 senza opzioni con lepton_pt, mem_phi 100'000 eventi \n",
    "#0.72716605849516347 senza opzioni con lepton_pt, mem_phi 10'000 eventi\n",
    "#high level features a:\n",
    "#max_depth 5: 0.77373192433167481\n",
    "#max_depth 4: 0.7748102315375196, gamma=0.3: 0.7750851890287791\n",
    "#max_depth 6: 0.77178583194465911\n",
    "# high level features b:\n",
    "#max_depth 6, gamma=0.3 0.78655990568943845\n",
    "# high level features c:\n",
    "#max_depth 6, gamma=0.3 0.78747491255687363\n",
    "# high level features c with Ht and pt:\n",
    "#max_depth 6, gamma=0.3 0.78959440814072357\n",
    "# high level features c with Ht only:\n",
    "#max_depth 6, gamma=0.3 0.78882205872533173\n",
    "# high level features d:\n",
    "#max_depth 6, gamma=0.3 0.78911150552696641\n",
    "# high level features e:\n",
    "#max_depth 6, gamma=0.3 0.78987168613515957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.80165832047956576, 0.002120279817989415)\n"
     ]
    }
   ],
   "source": [
    "#from rep.estimators import XGBoostClassifier\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "#xgboost_cv = cross_val_score(XGBoostClassifier(max_depth = 5, min_child_weight = 1, gamma=0),\n",
    "#                             training_data[high_level_features].astype(np.float64),\n",
    "#                             training_data.target.astype(np.int64), cv=4, scoring=\"roc_auc\")\n",
    "#print(xgboost_cv.mean(), xgboost_cv.std())\n",
    "\n",
    "\n",
    "#0.7668823025 senza opzioni con lepton_pt, mem_phi 100'000 eventi \n",
    "#0.72716605849516347 senza opzioni con lepton_pt, mem_phi 10'000 eventi\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "xgboost_bag_cv = cross_val_score(BaggingClassifier(base_estimator=XGBoostClassifier(max_depth = 6, min_child_weight = 1, gamma=0., colsample=1, nthreads=10),n_estimators=10),\n",
    "                             training_data[high_level_features].astype(np.float64),\n",
    "                             training_data.target.astype(np.int64), cv=4, scoring=\"roc_auc\")\n",
    "print(xgboost_bag_cv.mean(), xgboost_bag_cv.std())\n",
    "#boost_bagg = BaggingClassifier(base_estimator=XGBoostClassifier(max_depth = 5, min_child_weight = 1, gamma=0),n_estimators=34, n_jobs=10)\n",
    "#boost_bagg.fit(training_data[high_level_features].astype(np.float64), training_data.target.astype(np.int64))\n",
    "\n",
    "#high level features a\n",
    "###0.78144373296283975 con max_depth = 5\n",
    "###0.77968141225306831 con max_depth = 4\n",
    "###0.7823899079878065 con max_depth = 6, gamma=0.3 0.78169084626057739\n",
    "# high level features b:\n",
    "#max_depth 6, gamma=0.3 0.7972091448484645\n",
    "#max_depth 6, gamma=0 0.79791828545435561\n",
    "# high level features c:\n",
    "#max_depth 6, gamma=0. 0.7992048882561511\n",
    "# high level features c with Ht an pt\n",
    "#max_depth 6, gamma=0.0.80147524606003273\n",
    "# high level features c with Ht only\n",
    "#max_depth 6, gamma=0.  0.79897399081169285\n",
    "#high level features d:\n",
    "#max_depth 6, gamma=0 0.80011445909587442\n",
    "#high level features d:\n",
    "#max_depth 6, gamma=0 0.80165832047956576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=XGBoostClassifier(base_score=0.5, colsample=1, eta=0.3, features=None,\n",
       "         gamma=0, max_depth=6, min_child_weight=1, missing=-999.0,\n",
       "         n_estimators=10, nthreads=10, num_feature=None, random_state=0,\n",
       "         scale_pos_weight=1.0, subsample=1.0, verbose=0),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rep.estimators import XGBoostClassifier\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "#xgboost_cv = cross_val_score(XGBoostClassifier(max_depth = 5, min_child_weight = 1, gamma=0),\n",
    "#                             training_data[high_level_features].astype(np.float64),\n",
    "#                             training_data.target.astype(np.int64), cv=4, scoring=\"roc_auc\")\n",
    "#print(xgboost_cv.mean(), xgboost_cv.std())\n",
    "\n",
    "\n",
    "#0.7668823025 senza opzioni con lepton_pt, mem_phi 100'000 eventi \n",
    "#0.72716605849516347 senza opzioni con lepton_pt, mem_phi 10'000 eventi\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#xgboost_bag_cv = cross_val_score(BaggingClassifier(base_estimator=XGBoostClassifier(max_depth = 5, min_child_weight = 1, gamma=0),n_estimators=34),\n",
    "#                             training_data[high_level_features].astype(np.float64),\n",
    "#                             training_data.target.astype(np.int64), cv=4, scoring=\"roc_auc\")\n",
    "#print(xgboost_bag_cv.mean(), xgboost_bag_cv.std())\n",
    "boost_bagg = BaggingClassifier(base_estimator=XGBoostClassifier(max_depth = 6, min_child_weight = 1, gamma=0, \n",
    "                                                                colsample=1, n_estimators=10, nthreads=10))\n",
    "boost_bagg.fit(training_data[high_level_features].astype(np.float64), training_data.target.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Risultati:\n",
    "#xgboost bag 25 n_estimator: 748619196\n",
    "#xgboost bag 30 n_estimator: 74810733\n",
    "#xgboost bag 35 n_estimator: 74842935567290336\n",
    "#xgboost bag 34 n_estimator: 74889629284010684\n",
    "#\"                      , max depth 5: 0.74948804173465056\n",
    "# \" \"                                , min child 1, gamma 0: 0.75022381545276473\n",
    "# + colsample=0.8: 0.74879395566741258\n",
    "# + colsample= 0.8 su 100'000: 0.77806206257685062\n",
    "# colsample=1 su 100'000 0.77841176129880307\n",
    "# max depths 6?\n",
    "#se tolgo mjjj, 30 estimators: peggio scende"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rep.estimators import XGBoostClassifier\n",
    "xg = XGBoostClassifier(max_depth = 5, min_child_weight = 1, gamma=0, colsample=1)\n",
    "xg.fit(training_data[high_level_features].astype(np.float64), training_data.target.astype(np.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada on XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_on_xgb = cross_val_score(AdaBoostClassifier(base_estimator=XGBoostClassifier()),\n",
    "                              training_data[high_level_features].astype(np.float64), training_data.target.astype(np.int64), cv=4, scoring=\"roc_auc\")\n",
    "print(ada_on_xgb.mean(), ada_on_xgb.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xg_ada = AdaBoostClassifier(base_estimator=XGBoostClassifier())\n",
    "xg_ada.fit(training_data[high_level_features].astype(np.float64), training_data.target.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#0.71559484247046334 ada cross val: senza opzioni con lepton_pt, mem_phi 10'000 eventi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict validation sample (probability for each event)\n",
    "proba = xg.predict_proba(validation_data[high_level_features].astype(np.float64))\n",
    "#proba_ada = xg_ada.predict_proba(validation_data[high_level_features].astype(np.float64))\n",
    "#proba_boost_bag = boost_bagg.predict_proba(validation_data[high_level_features].astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict validation sample (probability for each event)\n",
    "#proba = xg.predict_proba(validation_data[high_level_features].astype(np.float64))\n",
    "#proba_ada = xg_ada.predict_proba(validation_data[high_level_features].astype(np.float64))\n",
    "proba_boost_bag = boost_bagg.predict_proba(validation_data[high_level_features].astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba\n",
    "proba_ada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute quality (ROC AUC) on the validation set (to prevent overestimating quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take probability to be 1 class to compute ROC AUC\n",
    "#\n",
    "roc_auc_score(validation_data.target, proba[:, 1])\n",
    "#0.73411680585983141 con xgb da solo, senza opzioni, lep_pt, mem_phi, 10'000 eventi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take probability to be 1 class to compute ROC AUC\n",
    "#\n",
    "roc_auc_score(validation_data.target, proba_ada[:, 1])\n",
    "#0.7176807190099479 con xgb da solo, senza opzioni, lep_pt, mem_phi, 10'000 eventi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79228100410996594"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take probability to be 1 class to compute ROC AUC\n",
    "#\n",
    "roc_auc_score(validation_data.target, proba_boost_bag[:, 1])\n",
    "#0.7176807190099479 con xgb da solo, senza opzioni, lep_pt, mem_phi, 10'000 eventi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaggle_proba = boost_bagg.predict_proba(test[high_level_features].astype(np.float64))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict test sample\n",
    "kaggle_proba = boost_bagg.predict_proba(test[high_level_features].astype(np.float64))[:, 1]\n",
    "#kaggle_proba = xg.predict_proba(test[high_level_features].astype(np.float64))[:, 1]\n",
    "kaggle_ids = test.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='datasets/xg_bagg_tuned_setoffeatures_e.csv' target='_blank'>datasets/xg_bagg_tuned_setoffeatures_e.csv</a><br>"
      ],
      "text/plain": [
       "/notebooks/higgs_kaggle/datasets/xg_bagg_tuned_setoffeatures_e.csv"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "def create_solution(ids, proba, filename='xg_bagg_tuned_setoffeatures_e.csv'):\n",
    "    \"\"\"saves predictions to file and provides a link for downloading \"\"\"\n",
    "    pandas.DataFrame({'event_id': ids, 'prediction': proba}).to_csv('datasets/{}'.format(filename), index=False)\n",
    "    return FileLink('datasets/{}'.format(filename))\n",
    "    \n",
    "create_solution(kaggle_ids, kaggle_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -lah datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
