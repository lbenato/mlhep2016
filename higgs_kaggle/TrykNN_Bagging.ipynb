{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "In this notebook we prepare a simple solution for the [kaggle challenge on higgs.](https://inclass.kaggle.com/c/mlhep-2016-higgs-detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the smallest part of training file and test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import root_numpy\n",
    "data = pandas.DataFrame(root_numpy.root2array('datasets/public_train_100000.root'))\n",
    "test = pandas.DataFrame(root_numpy.root2array('datasets/public_test.root'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training features\n",
    "\n",
    "Exclude `event_id`, `target` from the features set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = list(set(data.columns) - {'event_id', 'target'})\n",
    "#features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare high-level features for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#high_level_features = ['m_jj', 'm_jjj', 'm_jlv', 'm_wwbb', 'm_bb', 'm_wbb', 'm_lv']\n",
    "high_level_features = ['m_jj', 'm_jlv', 'm_wwbb', 'm_bb', 'm_wbb', 'm_lv', 'lepton_pt','mem_phi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot histograms for each high-level feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hist_params = {'normed': True, 'bins': 60, 'alpha': 0.4}\n",
    "## create the figure\n",
    "#plt.figure(figsize=(16, 25))\n",
    "#for n, feature in enumerate(high_level_features):\n",
    "#    # add sub plot on our figure\n",
    "#    plt.subplot(len(features) // 5 + 1, 3, n+1)\n",
    "#    # define range for histograms by cutting 1% of data from both ends\n",
    "#    min_value, max_value = numpy.percentile(data[feature], [1, 99])\n",
    "#    plt.hist(data.ix[data.target.values == 0, feature].values, range=(min_value, max_value), \n",
    "#             label='background', **hist_params)\n",
    "#    plt.hist(data.ix[data.target.values == 1, feature].values, range=(min_value, max_value), \n",
    "#             label='signal', **hist_params)\n",
    "#    plt.legend(loc='best')\n",
    "#    plt.title(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide training data into 2 parts \n",
    "`train_test_split` function is used to divide into 2 parts to preserve quality overestimating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data, validation_data = train_test_split(data, random_state=11, train_size=0.66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple knn from `sklearn` training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "#knn = KNeighborsClassifier(n_neighbors=100, metric='manhattan')\n",
    "#knn.fit(training_data[high_level_features], training_data.target)\n",
    "#knn_cv = cross_val_score(KNeighborsClassifier(),\n",
    "#                training_data[high_level_features],\n",
    "#                training_data.target,\n",
    "#                cv=4, n_jobs=4, scoring=\"roc_auc\")\n",
    "#print knn_cv.mean()\n",
    "#bagging_cv = cross_val_score(BaggingClassifier(base_estimator=KNeighborsClassifier(), n_jobs=4),\n",
    "#                             training_data[high_level_features],\n",
    "#                             training_data.target, scoring='roc_auc', cv=4)\n",
    "#print bagging_cv.mean()\n",
    "b = BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=70, metric='manhattan', n_jobs=20), n_jobs=10, n_estimators=20)\n",
    "b.fit(training_data[high_level_features], training_data.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### predict validation sample (probability for each event)\n",
    "#proba = knn.predict_proba(validation_data[high_level_features])\n",
    "probb = b.predict_proba(validation_data[high_level_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#probb\n",
    "roc_auc_score(validation_data.target, probb[:, 1])\n",
    "#0.74161 con 100\n",
    "#0.7262 con 10\n",
    "#0.74974 con 50\n",
    "#0.75104 con 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute quality (ROC AUC) on the validation set (to prevent overestimating quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take probability to be 1 class to compute ROC AUC\n",
    "#roc_auc_score(validation_data.target, proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict test sample\n",
    "kaggle_probb = b.predict_proba(test[high_level_features])[:, 1]\n",
    "kaggle_ids = test.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "def create_solution(ids, proba, filename='bagging_kNN.csv'):\n",
    "    \"\"\"saves predictions to file and provides a link for downloading \"\"\"\n",
    "    pandas.DataFrame({'event_id': ids, 'prediction': proba}).to_csv('datasets/{}'.format(filename), index=False)\n",
    "    return FileLink('datasets/{}'.format(filename))\n",
    "    \n",
    "create_solution(kaggle_ids, kaggle_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
